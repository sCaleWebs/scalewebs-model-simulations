[
  {
    "path": "posts/2022-04-13-beta-diversity-and-species-responses/",
    "title": "Beta diversity and species responses",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Andrew MacDonald",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-04-13",
    "categories": [],
    "contents": "\n\nContents\nWhy simulate data?\nFood web simulations\nsimulate incidence functions\n\n\n\n\nlibrary(tidyverse)\ntheme_set(theme_bw())\nsource(here::here(\"_posts/2022-04-13-beta-diversity-and-species-responses/simulation_functions.R\"))\n\n\n\nWhy simulate data?\nThe goal of this short document is to create simulated data which is resembles our sCaleWebs synthesis data. This data will be simulated from a statistical model. This lets us set the values for various effects, and observe their effects on the food web patterns we are trying to understand.\nIn my view, a simulated data approach has several interesting advantages:\nunderstanding our models ecological models can quickly become so complex, with many factors and emergent properities that it can be challenging to reason about them. Things like correlated predictors, sample size, and power can be investigated with\nvalidate and test any statistical methods we develop whatever approach we choose, it is helpful to study how it performs on simulated data. In our simulations, we know the truth – the values of specific parameters. A simple requirement for a model might be that it does not find an effect when none is there (no false positives) or that it usually finds an effect when one is present (limited false negatives)\nParameter recovery For models which return parameter estimates, we can check to see if the model accurately recovers the values of the parameters used to simulate the data. This can be very helpful, for example, in finding problems with identification.\nUnderstanding the data Our dataset is complex, and our food webs are somewhat unique. For example, we make local webs by filtering the community metaweb with a bromeliad-level species list. The consequences of this are challenging to intuit; not least because this differs from many other datasets, where replicated food webs are directly observed. Personally I find simulations helpful in understanding where a dataset comes from!\nThe simulations below have two parts: first, simulating plausible food webs; second, simulating responses to environmental gradients\nFood web simulations\nI want to simulate the food web in a plausible way. Some constraints:\nAll species except basal resources need a link\nmost species will have only 3 connections (ie they eat basal resources; they are decomposers)\nHere is an expression for the number of links.\n\npossibly with the constraint that the one link can’t be a cannibal!\n\\[\nL_i = (S - 1)p_i + 1\n\\]\nThe probability of a link, \\(p_i\\) is another way of thinking about the degree of a species.\nIn our dataset the modal species richness is 3 because most species are detritivores that eat all the basal resources. One simple way to represent this is to allow the node distribution to have an average centered on 3\n\nDo we want to have some kind of.. 3-inflated distribution for our links? treat detritivores as a predictor category? or would taxonomy soak up a lot of this?\nThe steps: * find the average p for a food web where most species eat 3 things * let each consumer have a different p * draw links for each predator\n\n\nn_basal <- 3\nS <- 12\n\nmean_p <- (n_basal - 1)/(S - 1)\n\nconsumer_probs <- rbeta(n = S - n_basal, mean_p * 3, (1 - mean_p) * 3)\n\nconsumer_links <- rbinom(S - n_basal, S - 1, prob = consumer_probs) + 1\n\ntibble(consumer_links) |> \n  count(consumer_links) |> \n  ggplot(aes(x = consumer_links, y = n)) + \n  geom_bar(stat = \"identity\") + \n  coord_cartesian(xlim = c(0, S))\n\n\n\n\nThe above uses the beta distribution to generate differences among consumers. However it is more flexible to use the logit scale:\n\n\nsimulate_degrees\n\n\nfunction (n_basal, S, degree_sd_logit = 0.3) \n{\n    mean_p <- (n_basal - 1)/(S - 1)\n    consumer_probs_logit <- plogis(qlogis(mean_p) + rnorm(S - \n        n_basal, mean = 0, sd = degree_sd_logit))\n    degrees <- rbinom(S - n_basal, S - 1, prob = consumer_probs_logit) + \n        1\n    return(degrees)\n}\n\ndegrees <- simulate_degrees(n_basal = 3, S = 12, degree_sd_logit = 0.3)\n\ntibble(degrees) |> \n  count(degrees) |> \n  ggplot(aes(x = degrees, y = n)) + \n  geom_bar(stat = \"identity\") + \n  coord_cartesian(xlim = c(0, S))\n\n\n\n\nsimulate incidence functions\n\\[\n\\begin{align}\nY_i &\\sim \\text{Binomial}(p, 1) \\\\\n\\text{logit}(p) &= a(\\phi - b) \\\\\n\\phi &= \\bar{\\phi} + \\beta_{e}X_e \\\\\n\\begin{bmatrix} a \\cr b\\ \\end{bmatrix} &\\sim \\text{MVN}(\\begin{bmatrix} \\bar{a} \\cr \\bar{b}\\ \\end{bmatrix}, \\Sigma)\n\\end{align}\n\\]\n\n\nnsites <- 45\nx <- runif(nsites, min = -3, max = 3)\n\nbar_phi <- -1\nbeta_phi <- .3\n\nphi <- bar_phi + beta_phi * x\n\nplot(x, plogis(phi))\n\n\n\n\nsimulate correlated \\(a\\) and \\(b\\)\n\n\ncorr_mat <- matrix(c(1, .5, .5, 1), nrow = 2)\nsds <- c(.4, 1)\n\nsig <- diag(sds) %*% corr_mat %*% diag(sds)\n\nconsumer_a_b <- MASS::mvrnorm(S - n_basal, mu = c(2, -3), Sigma = sig)\n\n\n\nmatch species and sites to the coefs:\n\n\nfake_data <- expand_grid(site = 1:nsites, sp = 1:(S - n_basal)) |> \n  mutate(\n    x = x[site],\n    logit_prob = consumer_a_b[sp, 1] * (phi[site] - consumer_a_b[sp, 2]))\n\nfake_data |> \n  ggplot(aes(x = x, y = logit_prob, group = sp)) + \n  geom_line()\n\n\n\nfake_data |> \n  ggplot(aes(x = x, y = plogis(logit_prob), group = sp)) + \n  geom_line()\n\n\n\n\nNow, we need to sample species compositions from this curve\n\n\nfake_data_obs <- fake_data |> \n  mutate(prb = plogis(logit_prob),\n         presabs = rbinom(nrow(fake_data), size = 1, prob = prb)) |> \n  mutate(sp = paste0(\"sp\", sp),\n         site = paste0(\"site\", site)) \n\nfake_rich <- fake_data_obs |> \n  group_by(site, x) |> \n  summarize(richness = sum(presabs)) |> \n  ungroup()\n\nfake_rich |> \n  ggplot(aes(x = x, y = richness)) + geom_point()\n\n\n\n\nFinally, we can tweak the simulation to include correlations between the response to the environment and the number of nodes\nCould then look at the relationship between connectance and the environment, for example\n\n\nsxs <- fake_data_obs |> \n  select(site, sp, presabs) |> \n  pivot_wider(names_from = sp, values_from = presabs,values_fill = 0) |> \n  column_to_rownames(\"site\")\n\n\n\n\n\nsite_lcbd <- sxs |> \n  adespatial::beta.div() |> \n  pluck(\"LCBD\") |> \n  enframe(name = \"site\", value = \"lcbd\")\n\nfake_rich |> \n  left_join(site_lcbd) |> \n  ggplot(aes(x = richness, y = lcbd)) + geom_point()\n\n\n\n\n\n\nfake_rich |> \n  left_join(site_lcbd) |> \n  ggplot(aes(x = x, y = lcbd)) +\n  geom_point() + \n  stat_smooth(method = \"gam\")\n\n\n\n\n\n\n\n",
    "preview": "posts/2022-04-13-beta-diversity-and-species-responses/beta-diversity-and-species-responses_files/figure-html5/links-1.png",
    "last_modified": "2022-04-14T05:38:23-04:00",
    "input_file": "beta-diversity-and-species-responses.knit.md"
  }
]
